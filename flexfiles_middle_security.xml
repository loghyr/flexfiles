<!-- Copyright (C) The IETF Trust (2014) -->
<!-- Copyright (C) The Internet Society (2014) -->

<section anchor="sec:fencing" title="Client Fencing">
  <t>
    In cases where clients are uncommunicative and their lease has
    expired or when clients fail to return recalled layouts within
    a lease period, at the least the server MAY revoke client layouts
    and reassign these resources to
    other clients (see Section 12.5.5 in <xref target='RFC5661' />).
    To avoid data corruption, the metadata server MUST fence
    off the revoked clients from the respective data files as described
    in <xref target='sec:sec_models' />.
 </t>
</section>

<section anchor="sec:security" title="Security Considerations">
  <t>
    The pNFS extension partitions the NFSv4.1+ file system protocol
    into two parts, the control path and the data path (storage
    protocol).  The control path contains all the new operations
    described by this extension; all existing NFSv4 security mechanisms
    and features apply to the control path (see Sections 1.7.1 and 2.2.1
    of <xref target='RFC5661' />).  The combination of components in
    a pNFS system is required to preserve the security properties of
    NFSv4.1+ with respect to an entity accessing data via a client,
    including security countermeasures to defend against threats that
    NFSv4.1+ provides defenses for in environments where these threats
    are considered significant.
  </t>

  <t>
    The metadata server enforces the file access-control policy at
    LAYOUTGET time.  The client should use RPC authorization credentials
    for getting the layout for the requested iomode (READ or RW) and
    the server verifies the permissions and ACL for these credentials,
    possibly returning NFS4ERR_ACCESS if the client is not allowed the
    requested iomode.  If the LAYOUTGET operation succeeds the client
    receives, as part of the layout, a set of credentials allowing
    it I/O access to the specified data files corresponding to the
    requested iomode.  When the client acts on I/O operations on behalf
    of its local users, it MUST authenticate and authorize the user by
    issuing respective OPEN and ACCESS calls to the metadata server,
    similar to having NFSv4 data delegations.
  </t>

  <t>
    If access is allowed, the client uses the corresponding (READ or RW)
    credentials to perform the I/O operations at the data file's storage
    devices.  When the metadata server receives a request to change a
    file's permissions or ACL, it SHOULD recall all layouts for that file
    and then MUST fence off any clients still holding outstanding layouts
    for the respective files by implicitly invalidating the previously
    distributed credential on all data file comprising the file in
    question.  It is REQUIRED that this be done before committing to the
    new permissions and/or ACL.  By requesting new layouts, the clients
    will reauthorize access against the modified access control metadata.
    Recalling the layouts in this case is intended to prevent clients
    from getting an error on I/Os done after the client was fenced off.
  </t>

  <section anchor="ss:security:krb5" title="RPCSEC_GSS and Security Services">
    <section anchor="ss:sec:krb5:lc" title="Loosely Coupled">
      <t>
        RPCSEC_GSS version 3 (RPCSEC_GSSv3) <xref target='RFC7861' />
        could be used to authorize the client to the storage device on
        behalf of the metadata server.  This would require that each of
        the metadata server, storage device, and client would have to
        implement RPCSEC_GSSv3 via an RPC-application-defined
        structured privilege assertion in a manner described in Section 4.9.1
        of <xref target='RFC7862' />. These requirements do not match
        the intent of the loosely coupled model that the storage device
        need not be modified. (Note that this does not preclude the use
        of RPCSEC_GSSv3 in a loosely coupled model.)
      </t>

      <t>
        Under this coupling model, the principal used to authenticate
        the metadata file is different than that used to authenticate
        the data file.  For the metadata server, the RPC credentials
        would be generated by the same source as the client.
        For RPC credentials to the data on the storage device, the
        metadata server would be responsible for their generation.
        Such "credentials" SHOULD be limited to just the data file
        be accessed.  Using Kerberos V5 GSS-API <xref target='RFC4121' />,
        some possible approaches would be:

        <list style="symbols">
          <t>
            a dedicated/throwaway client principal name akin to the
            synthetic uid/gid schemes.
          </t>

          <t>
            authorization data in the ticket.
          </t>

          <t>
            an out-of-band scheme between the client and metadata server.
          </t>
        </list>
      </t>

      <t>
        Depending on the implementation details, fencing would then be
        controlled either by expiring the credential or by modifying
        the synthetic uid or gid on the data file. I.e., if the
        credentials are at a finer granularity than the synthetic
        ids, it might be possible to also fence just one client from
        the file.
      </t>

    </section>

    <section anchor="ss:sec:krb5:tc" title="Tightly Coupled">
      <t>
        With tight coupling, the principal used to access the metadata
        file is exactly the same as used to access the data file.
        The storage device can use the control protocol to validate any
        RPC credentials. As a result there are no security issues related
        to using RPCSEC_GSS with a tightly coupled system.  For example,
        if Kerberos V5 GSS-API <xref target='RFC4121' /> is used as the
        security mechanism, then the storage device could use a control
        protocol to validate the RPC credentials to the metadata server.
      </t>
    </section>
  </section>
</section>
